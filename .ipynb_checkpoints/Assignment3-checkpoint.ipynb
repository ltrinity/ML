{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Python\n",
    "\n",
    "\n",
    "For this course, we are going to use Jupyter notebook as our environment for developing Python code.\n",
    "refer to https://jupyter.readthedocs.io/en/latest/content-quickstart.html on the instructions how to install it, the easiest way is to install from Anaconda (https://www.anaconda.com/download/) website, make sure you install with Python 3.6.\n",
    "\n",
    "Also, it is good for the students who are not familiar with python (or they need a quick refreshment) to follow Jim Bagrow tutorial http://bagrow.com/ds1/whirlwindtourpython/00-Title.html. \n",
    "\n",
    "All the assignments to be written in Python 3.6 and can be run using Jupyter on one of the following Internet browsers (Chrome, Safari or Firefox), these are the browsers that officially supported by jupyter.\n",
    "\n",
    "<u> Note: for this assignment, submit your local copy of this page, running on IPython. Submit the file to Blackboard under Assignment3 using this file format:</u> <b>Yourfirstname_lastname_Assignment3.ipynb</b> \n",
    "\n",
    "#### <b>Deadline</b>: <u>Friday, Oct-18-2019 11:59 PM.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbpresent": {
     "id": "71b06413-b3c8-4d8a-8162-c7f97e8638ff"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "022c0cf1-20b7-4df3-bc1d-c54d2df2cf0a"
    }
   },
   "source": [
    "# Assignment 3 -- Part 1\n",
    "\n",
    "In this part, you will use SVM from sklearn to classify non-linearly sperable datasets. \n",
    "\n",
    "Hint: Refer to the example in sklearn http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html, you can use this code or part of it in your solutions.\n",
    "\n",
    "Load (using load_breast_cancer) datasets from sklearn (datasets.load_breast_cancer()):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "print(data['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7b5712e6-b08b-4c78-96e5-d6c179cb2216"
    }
   },
   "source": [
    "### Part 1, Q1  --  [25 pts]\n",
    "\n",
    "1. In this question, you need to find the best SVM kernel that fit the data. Use built-in SVM functions from scikit learn Library. Evaluate 'linear', 'poly', 'rbf', 'sigmoid' Kernels using the default parameters as they aren't biased towards one of the kernels. Remember that in order to evaluate kernels or any hyper param you need to use cross-validation method. use k=50 for this question. Comment on the results.\n",
    "\n",
    "2. Which scoring metric you would like to use? justify your answer.\n",
    "\n",
    "Note: You can use built-in scikit learn function for this question and all other questions in this assignment else it is mentioned not to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "Accuracy: 0.963 (+/- 0.224)\n",
      "sigmoid\n",
      "Accuracy: 0.980 (+/- 0.158)\n",
      "poly\n",
      "Accuracy: 0.900 (+/- 0.346)\n",
      "rbf\n",
      "Accuracy: 0.973 (+/- 0.181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luket\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 39 members, which is too few. The minimum number of members in any class cannot be less than n_splits=50.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\luket\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 39 members, which is too few. The minimum number of members in any class cannot be less than n_splits=50.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\luket\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 39 members, which is too few. The minimum number of members in any class cannot be less than n_splits=50.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\luket\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 39 members, which is too few. The minimum number of members in any class cannot be less than n_splits=50.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#end import\n",
    "#extract features and target vectors from input dataset\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_trainScaled=scaler.fit_transform(X_train)\n",
    "X_testScaled=scaler.fit_transform(X_test)\n",
    "#create models with each type of kernel\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "         svm.SVC(kernel='sigmoid', gamma ='auto', C=1.0),\n",
    "         svm.SVC(kernel='poly', gamma ='auto', C=1.0),\n",
    "         svm.SVC(kernel='rbf', gamma ='auto', C=1.0))\n",
    "#fit the models\n",
    "models = (clf.fit(X_trainScaled,y_train) for clf in models)\n",
    "#evaluate the models using cross validation\n",
    "for model in models:\n",
    "    print(model.kernel)\n",
    "    prediction=model.predict(X_testScaled)\n",
    "    metrics.accuracy_score(prediction,y_test)\n",
    "    scores = cross_val_score(model, X_testScaled, y_test, cv=50)\n",
    "    print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3a0e4064-e0d5-43bd-8793-4ce5742de906"
    }
   },
   "source": [
    "## The sigmoid kernel is both the most accurate and has the lowest variance. Accuracy and variance are quantified by taking the average over all splits, this ensures that each random test/train split is weighted equally in evaluation of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "342e80f3-8091-415c-b362-61cd2365ff7d"
    }
   },
   "source": [
    "### Part 1, Q2  --  [25 pts]\n",
    "\n",
    "Using random search, what are the optimum hyperparameters for each kernel? \n",
    "For this question, use only a few numbers of iterations when you do a random search (no need to run for long hours). Add to that, also be smart when you select the scale for the C, gamma and class_weight so that you can find the best params. Which SVM kernel achieving the highest performance?\n",
    "\n",
    "Note: You can use RandomizedSearchCV function from the scikit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "nbpresent": {
     "id": "a90d24af-7c70-415a-9909-495ba485a1bf"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.10 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.602, 'C': 30.724999999999977}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.419, 'C': 49.16499999999996}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.305, 'C': 30.043999999999976}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.154, 'C': 19.892999999999986}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.0, 'C': 18.323999999999987}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.078, 'C': 43.133999999999965}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.504, 'C': 45.03799999999996}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.706, 'C': 24.41399999999998}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.2939999999999998, 'C': 35.10999999999997}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.198, 'C': 20.471999999999984}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.677, 'C': 43.96599999999996}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.775, 'C': 26.507999999999978}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.227, 'C': 7.233999999999994}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.14500000000000002, 'C': 22.932999999999982}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.367, 'C': 38.133999999999965}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.169, 'C': 15.865999999999987}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.091, 'C': 24.77499999999998}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 1.476, 'C': 40.20799999999996}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.34, 'C': 45.14499999999996}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.059)\n",
      "Parameters: {'gamma': 0.28, 'C': 34.21299999999997}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=1):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"C\": np.arange(.01, 50, .001),\n",
    "             \"gamma\": np.arange(0.001, 2, 0.001)}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "model = svm.SVC(kernel='linear')\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_testScaled, y_test)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f552aeba-4559-461d-882a-823ba5425db4"
    }
   },
   "source": [
    "### (Graduate students only)\n",
    "\n",
    "### Part 1, Q3  --  [10 pts]\n",
    "\n",
    "Randomly select 20% of the data for testing and the rest for training.\n",
    "\n",
    "Plot the decision surface for \"worse SVM\", \"best SVM\" found in part b and report the performance for each, you may use built-in sklean functions for visualization.\n",
    "\n",
    "Note: For visualization you need to work on two-dimensional feature space. To do so, use PCA to reduce the number of the features to 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cd1818e8-bb92-403c-af51-aaad4450235e"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "394b37bb-6e40-422e-b3c9-c622c46ab976"
    }
   },
   "source": [
    "# Assignment 3 -- Part 2\n",
    "\n",
    "In this part, you will use the decision tree from sklearn to classify non-linearly separable datasets. \n",
    "\n",
    "\n",
    "Load Car Evaluation Data Set from https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data, read the dataset description and get familiar with the dataset attributes https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names\n",
    "\n",
    "This dataset includes strings, you might need to convert them to numbers, in this case, you might need to use methods like preprocessing.LabelEncoder(). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "06adccbc-446c-49c2-af1a-5688479b7251"
    }
   },
   "source": [
    "### Part 2, Q1-- [25 pts]\n",
    "\n",
    "Use the decision tree to classify the dataset (evaluate cars to one of the four classes unacc, acc, good, v-good). Use cross-validation while reporting your results. You can use sklearn.tree.DecisionTreeClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f9acd257-ab12-4275-868d-133fd6e2e5ae"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f97aa916-f0ed-4776-95e7-2e92c66f1add"
    }
   },
   "source": [
    "### Part 1, Q2 [25 pts]\n",
    "\n",
    "What is the optimum min_samples_split (The minimum number of samples required to split an internal node), does it make sense? Why?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fceba820-64d6-40e3-9223-36de70bac16b"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d83b28ba-d22d-415e-9ccd-32f809507501"
    }
   },
   "source": [
    "### (Graduate students only)\n",
    "\n",
    "### Part 1, Q3 [15 pts]\n",
    "\n",
    "Implement random forest classifier by defining multiple (DecisionTreeClassifier)'s from sklearn. You can use the max_features from DecisionTreeClassifier. Lastly, compare your results to RandomForestClassifier from sklearn.\n",
    "\n",
    "Note: In this part implement the bagging/ensemble by yourself without calling built-in functions from sklearn (you may still use RandomForestClassifier from sklearn with max_features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
