{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Python\n",
    "\n",
    "\n",
    "For this course, we are going to use Jupyter notebook as our environment for developing Python code.\n",
    "refer to https://jupyter.readthedocs.io/en/latest/content-quickstart.html on the instructions how to install it, the easiest way is to install from Anaconda (https://www.anaconda.com/download/) website, make sure you install with Python 3.6.\n",
    "\n",
    "Also, it is good for the students who are not familiar with python (or they need a quick refreshment) to follow Jim Bagrow tutorial http://bagrow.com/ds1/whirlwindtourpython/00-Title.html. \n",
    "\n",
    "All the assignments to be written in Python 3.6 and can be run using Jupyter on one of the following Internet browsers (Chrome, Safari or Firefox), these are the browsers that officially supported by jupyter.\n",
    "\n",
    "<u> Note: for this assignment, submit your local copy of this page, running on IPython. Submit the file to Blackboard under Assignment5 using this file format:</u> <b>Yourfirstname_lastname_Assignment5.ipynb</b> \n",
    "\n",
    "#### <b>Deadline</b>: <u>Dec-6-2019 11:59 PM.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started: Installing Numpy, Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level Python API that allows you to easily construct, train, and apply neural networks.\n",
    "However, Keras is not a neural network library itself and depends on one of several neural network backends. We will use the Tensorflow backend. TensorFlow is an open-source library for neural networks (and other mathematical models based on sequences of matrix and tensor computations), originally developed by Google.Also, Keras uses numpy data structures. \n",
    "\n",
    "Installing Numpy, TensorFlow and Keras: \n",
    "\n",
    "We suggest that you use the Python package management system pip. \n",
    "On most systems, the following commands will work:\n",
    "\n",
    "- $ pip install numpy matplotlib.\n",
    "\n",
    "- $ pip install tensorflow\n",
    "\n",
    "- $ pip install keras\n",
    "\n",
    "### OR Using Anaconda (Easy and Prefered)\n",
    "\n",
    "- $ conda install keras scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this will likely install the CPU version of TensorFlow that does not use the GPU to speed up neural network training. For this assignment, training on the CPU will be sufficient, but if your computer has a GPU (or you want to try running the assignment in the cloud), follow the installation instructions on the tensorflow page. \n",
    "\n",
    "If you get stuck during the installation, you can find installation instructions for each package here: \n",
    "\n",
    "- Tensorflow: https://www.tensorflow.org/install/ \n",
    "- Keras: https://keras.io/#installation \n",
    "\n",
    "<b>I highly recommend that </b> you read and run these tutorials before you start this assignment. \n",
    "- https://www.tensorflow.org/tutorials/keras/classification\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### Introduction\n",
    "In this assignment you will use the Keras Neural Network API for Python to build neural networks for image classification. \n",
    "\n",
    "\n",
    "#### Data Set\n",
    "\n",
    "We will work on the CIFAR-10 image data set  described here: https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "The data set contains 60.000 images labeled with 10 different categories:\n",
    "\n",
    "Numeric ID\tCategory Name\n",
    "- 0\tairplane\n",
    "- 1\tautomobile\n",
    "- 2\tbird\n",
    "- 3\tcat\n",
    "- 4\tdeer\n",
    "- 5\tdog\n",
    "- 6\tfrog\n",
    "- 7\thorse\n",
    "- 8\tship\n",
    "- 9\ttruck\n",
    "\n",
    "\n",
    "Each image is 32x32 pixels large and there are three color channels (red, green blue). Each image can therefore be represented as three 32x32 matrices or one 32x32x3 cube.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential \n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. (20 pts) - Loading the CIFAR-10 Data\n",
    "\n",
    "The following code fragment imports the CIFAR-10 data using Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data into training and validation (40000 for training, and 10000 for validation). Thus you have xtrain, ytrain, xvalid, yvalid, xtest, and ytest are numpy n-dimension arrays contains the training validation and testing data.\n",
    "\n",
    "The input training data (xtrain) is a 4-dimensional array containing 40000 images, each of them a 32x32x3 tensor. Numpy arrays can be indexed like nested Python lists, so xtrain[0] will give you the first 32x32x3 image.\n",
    "\n",
    "The input label (ytrain) is a vector containing the numeric class for each image (see table above for what the numeric IDs mean). For example, xtrain[0] is an image of a frog and therefore ytrain[0] contains the value 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Images\n",
    "If you want to take a look at the individual images, you can do so using matplotlib (this step is optional). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xtrain[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.[20 Pnts] 1-hot representation for class labels\n",
    "\n",
    "The output layer of the neural networks we will train will contain 10 neurons corresponding to the 10 classes. The classifier predicts the class whose corresponding neuron has the highest activation. We need to convert the numeric indices for each image into a 1-hot vector of length 10, so that the for class label n the n-th element is 1 and all other elements are 0. For example, if the class label is 6, we should get the 1-hot vector [0 0 0 0 0 0 1 0 0 0].\n",
    "The class labels for the entire training and set should then be represented as a 50000x10 matrix, and the testing data as a 10000x10 matrix (there are 10k test images). \n",
    "\n",
    "Write the function load_cifar10(), which should load the cifar-10 data as described above and should return 6 numpy arrays xtrain, ytrain_1hot, xval, yval_1hot, xtest, ytest_1hot. Your function should convert the y arrays into the 1-hot representation. You can either do this using loops (slow), using numpy fancy indexing (see numpy documentation), or by using appropriate functions in the numpy or Keras API. \n",
    "\n",
    "Your function should also do the following normalization on the data. The R,G and B values for each pixel range between 0 and 255. Before returning the training data, normalize it so that these value range between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    ''' '''    \n",
    "    # add your code here...\n",
    "    \n",
    "    return xtrain, xval, xtest, ytrain_1hot, yval_1hot, ytest_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain_1hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xval.shape)\n",
    "print(yval_1hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(xtest.shape)\n",
    "print(ytest_1hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_1hot[0], yval_1hot[1], ytest_1hot[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. [20 Pnts]  In this task, you will implement an MLP network using keras.Sequential method with:\n",
    "\n",
    "- Batch size: 16. \n",
    "- Number of hidden layers: 1 (100 neuron).\n",
    "- use SGD optimizer, Learning Rate: 0.01.\n",
    "- #of epochs 10.\n",
    "- Use softmax layer for your output.\n",
    "- use Relu as your activation function.\n",
    "\n",
    "Keep all other hyperparameters (activation function, etc.) at their default settings.\n",
    "\n",
    "\n",
    "Find the performance (accuracy) of your model on the validation set and test set after training for 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. [10 Pnts] How many parameters in the model implemented in b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. [10 Pnts] At which epoch your model starts to overfit? Do you think early stopping would be a good solution to avoid overfitting in this case, explain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "342e80f3-8091-415c-b362-61cd2365ff7d"
    }
   },
   "source": [
    "f. [40 pts] You must have noticed that one needs to set several parameters—such as the number of hidden layers, the number of neurons in each hidden layer, the non-linearity or activation function to be used, etc. These quantities are known as the hyper-parameters of the network. They need to be specified by the user creating the neural network model.\n",
    "\n",
    "In this task, you will evaluate the performance of your network for varying values of hyperparameters. Keeping the rest of the values constant (and equal to the default values), adjust the values of parameters as described below. Find the performance (accuracy) of your model on the validation set and plot a trend graph for each of the following.\n",
    "\n",
    "- Batch size: 32, 64, 128 (default 32).\n",
    "- Number of hidden layers: 1, 2, 4 (default 2).\n",
    "- SGD optimizer, Learning Rate: 0.001, 0.01, 0.1, 1 (default 0.01).\n",
    "- Use 10 epochs for all the experiments.\n",
    "- activation function Relu for all the experiments.\n",
    "\n",
    "Use these values to create the most successful model you can (evaluated based on validation scores) and report its accuracy on the test data. Keep all other hyperparameters (number of epochs, activation function, etc.) at their default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Par2 (This part is for Graduate students only, it is optional for undergraduates with extra cridets )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you are going to train a convolutional neural network on CIFAR-10  dataset from part 1, refer to part1 to use same training, validation and testing datasets splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. [30 points] Define the model as indicated in the code below. The model is defined as follows:\n",
    "\n",
    "- An input that is 32x32x3 dimensional vector.\n",
    "- Reshape the input as 32x32x3 images (it is a dataset with color images)\n",
    "- A convolutional layer with 32 filters of shape 12x12x3 and a ReLU non-linearity (with stride (2, 2) and no padding)\n",
    "- A convolutional layer with 64 filters of shape 5x5x32 and a ReLU non-linearity (with stride (1, 2) and padding to maintain size)\n",
    "- A max_pooling layer of shape 2x2\n",
    "- A fully connected layer taking all the outputs of the max_pooling layer to 1024 units and ReLU nonlinearity\n",
    "- A fully connected layer taking 1024 units to 10 no activation function (the softmax non-linearity will be included in the loss function rather than in the model) \n",
    "- Use AdamOptimizer \n",
    "- use the Accuracy as your metric... Accuray is simply defined as the fraction of data correctly classified\n",
    "- initially pick the learning rate to be 0.05 (if this learning rate does not work, pick different learning rate) with decay step of 0.95 every 2000 iterations\n",
    "\n",
    "\n",
    "write the code to train the model written, train for 15 epochs with a  batch size of 128. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hint: start from known architecture then modify the code to match the numbers listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. [10 points] Find better convolutional neural network architecture that give better results (at least enhancment of 5.0%) than the one built in part a (prove experimentally). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
